{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\21265\\anaconda3\\envs\\tfpy39\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.6.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.6.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_hub as hub \n",
    "from sklearn.metrics import mean_absolute_error \n",
    "import numpy as np \n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PrefetchDataset shapes: ((None, 10, 224, 224, 3), (None, 5)), types: (tf.float32, tf.float32)>,\n",
       " <PrefetchDataset shapes: ((None, 10, 224, 224, 3), (None, 5)), types: (tf.float32, tf.float32)>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = tf.data.experimental.load('./data/faces/train_ds') \\\n",
    "    .cache().shuffle(buffer_size=1000, seed=42).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "valid_ds = tf.data.experimental.load('./data/faces/valid_ds') \\\n",
    "    .cache().shuffle(buffer_size=1000, seed=42).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = keras.applications.VGG16(include_top=False, weights='imagenet', pooling='max')\n",
    "vgg16.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Vit-B16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_extractor = hub.KerasLayer(\"https://www.kaggle.com/models/spsayakpaul/vision-transformer/frameworks/TensorFlow2/variations/vit-b16-fe/versions/1/\", trainable=False) # ../../vit_b16_fe/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Face model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.layers.Input(shape=(10,224,224,3), name='Input')\n",
    "\n",
    "# First model \n",
    "x      = keras.layers.TimeDistributed(keras.layers.Rescaling(scale=1./255.0), name='Rescaling')(inputs)\n",
    "x      = keras.layers.TimeDistributed(vgg16, name='vgg16')(x)\n",
    "x      = keras.layers.LSTM(units=128, return_sequences=True)(x)\n",
    "x      = keras.layers.LSTM(units=64)(x)\n",
    "x      = keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "x      = keras.layers.Dense(units=1024)(x)\n",
    "x      = keras.layers.Dense(units=512, activation='relu')(x)\n",
    "\n",
    "\n",
    "# Second model \n",
    "y      = keras.layers.TimeDistributed(keras.layers.Rescaling(scale=1./127.5, offset=-1))(inputs)\n",
    "\n",
    "# vit_extractor = hub.KerasLayer(\"../../vit_b16_fe/\", trainable=False) # ../../vit_b16_fe/\n",
    "vit_extractor.compute_output_shape = lambda x: (x[0], 768)\n",
    "\n",
    "y      = keras.layers.TimeDistributed(vit_extractor)(y)\n",
    "y      = keras.layers.LSTM(units=128, return_sequences=True)(y)\n",
    "y      = keras.layers.LSTM(units=64)(y)\n",
    "y      = keras.layers.Dropout(0.2)(y)\n",
    "y      = keras.layers.Dense(units=1024)(y)\n",
    "y      = keras.layers.Dense(units=512, activation='relu')(y)\n",
    "\n",
    "\n",
    "# Averaget two models\n",
    "z      = keras.layers.Average()([x,y])\n",
    "\n",
    "z      = keras.layers.Dense(256, activation='relu')(z)\n",
    "z      = keras.layers.Dropout(0.5)(z)\n",
    "\n",
    "z      = keras.layers.Dense(5, activation='sigmoid')(z)\n",
    "\n",
    "model  = keras.models.Model(inputs=inputs, outputs=z)\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = datetime.datetime.now().strftime(\"%m%d_%H%M%S\")\n",
    "\n",
    "optimizer      = tfa.optimizers.RectifiedAdam()\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=10, verbose=0)\n",
    "check_point    = keras.callbacks.ModelCheckpoint(filepath='./weights/face/'+str(t)+'/face.t5',\n",
    "                             monitor='val_mae',\n",
    "                             mode='min',\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True,\n",
    "                             verbose=0)\n",
    "\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - 357s 1s/step - loss: 0.0199 - mae: 0.1128 - val_loss: 0.0166 - val_mae: 0.1030\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - 256s 1s/step - loss: 0.0168 - mae: 0.1040 - val_loss: 0.0176 - val_mae: 0.1062\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - 240s 1s/step - loss: 0.0157 - mae: 0.1004 - val_loss: 0.0152 - val_mae: 0.0986\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - 214s 1s/step - loss: 0.0148 - mae: 0.0971 - val_loss: 0.0151 - val_mae: 0.0978\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - 214s 1s/step - loss: 0.0144 - mae: 0.0958 - val_loss: 0.0149 - val_mae: 0.0970\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - 214s 1s/step - loss: 0.0136 - mae: 0.0932 - val_loss: 0.0160 - val_mae: 0.1013\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - 213s 1s/step - loss: 0.0131 - mae: 0.0916 - val_loss: 0.0134 - val_mae: 0.0920\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - 213s 1s/step - loss: 0.0128 - mae: 0.0903 - val_loss: 0.0139 - val_mae: 0.0942\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - 213s 1s/step - loss: 0.0121 - mae: 0.0879 - val_loss: 0.0130 - val_mae: 0.0906\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - 213s 1s/step - loss: 0.0114 - mae: 0.0853 - val_loss: 0.0141 - val_mae: 0.0939\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - 213s 1s/step - loss: 0.0112 - mae: 0.0844 - val_loss: 0.0138 - val_mae: 0.0931\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - 213s 1s/step - loss: 0.0103 - mae: 0.0810 - val_loss: 0.0128 - val_mae: 0.0898\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - 213s 1s/step - loss: 0.0100 - mae: 0.0797 - val_loss: 0.0131 - val_mae: 0.0911\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - 213s 1s/step - loss: 0.0100 - mae: 0.0799 - val_loss: 0.0130 - val_mae: 0.0910\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - 213s 1s/step - loss: 0.0093 - mae: 0.0771 - val_loss: 0.0128 - val_mae: 0.0900\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - 213s 1s/step - loss: 0.0088 - mae: 0.0746 - val_loss: 0.0127 - val_mae: 0.0895\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - 213s 1s/step - loss: 0.0088 - mae: 0.0745 - val_loss: 0.0128 - val_mae: 0.0898\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - 213s 1s/step - loss: 0.0084 - mae: 0.0730 - val_loss: 0.0127 - val_mae: 0.0891\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - 213s 1s/step - loss: 0.0080 - mae: 0.0711 - val_loss: 0.0125 - val_mae: 0.0887\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - 213s 1s/step - loss: 0.0078 - mae: 0.0703 - val_loss: 0.0128 - val_mae: 0.0900\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - 213s 1s/step - loss: 0.0080 - mae: 0.0709 - val_loss: 0.0145 - val_mae: 0.0956\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - 215s 1s/step - loss: 0.0077 - mae: 0.0699 - val_loss: 0.0126 - val_mae: 0.0890\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - 214s 1s/step - loss: 0.0073 - mae: 0.0680 - val_loss: 0.0129 - val_mae: 0.0900\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - 214s 1s/step - loss: 0.0072 - mae: 0.0671 - val_loss: 0.0129 - val_mae: 0.0900\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - 213s 1s/step - loss: 0.0069 - mae: 0.0660 - val_loss: 0.0141 - val_mae: 0.0944\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - 213s 1s/step - loss: 0.0067 - mae: 0.0651 - val_loss: 0.0127 - val_mae: 0.0894\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - 217s 1s/step - loss: 0.0064 - mae: 0.0633 - val_loss: 0.0126 - val_mae: 0.0892\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - 214s 1s/step - loss: 0.0064 - mae: 0.0633 - val_loss: 0.0129 - val_mae: 0.0901\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - 214s 1s/step - loss: 0.0063 - mae: 0.0628 - val_loss: 0.0123 - val_mae: 0.0881\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - 215s 1s/step - loss: 0.0060 - mae: 0.0615 - val_loss: 0.0138 - val_mae: 0.0932\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - 230s 1s/step - loss: 0.0058 - mae: 0.0607 - val_loss: 0.0128 - val_mae: 0.0897\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - 246s 1s/step - loss: 0.0057 - mae: 0.0601 - val_loss: 0.0129 - val_mae: 0.0898\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - 235s 1s/step - loss: 0.0056 - mae: 0.0595 - val_loss: 0.0129 - val_mae: 0.0902\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - 214s 1s/step - loss: 0.0056 - mae: 0.0596 - val_loss: 0.0130 - val_mae: 0.0904\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - 215s 1s/step - loss: 0.0057 - mae: 0.0596 - val_loss: 0.0131 - val_mae: 0.0907\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - 215s 1s/step - loss: 0.0055 - mae: 0.0588 - val_loss: 0.0129 - val_mae: 0.0902\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - 213s 1s/step - loss: 0.0053 - mae: 0.0578 - val_loss: 0.0133 - val_mae: 0.0918\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - 218s 1s/step - loss: 0.0051 - mae: 0.0567 - val_loss: 0.0128 - val_mae: 0.0899\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - 214s 1s/step - loss: 0.0050 - mae: 0.0563 - val_loss: 0.0130 - val_mae: 0.0903\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, validation_data=valid_ds, batch_size=32, epochs=100, callbacks=[early_stopping, check_point])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load wights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2335f515700>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('./weights/face/0225_154249/face.t5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_LoadDataset shapes: ((None, 10, 224, 224, 3), (None, 5)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ds = tf.data.experimental.load('./data/faces/valid_ds') \n",
    "valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 117s 1s/step - loss: 0.0123 - mae: 0.0881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91.19105786085129"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, mae = model.evaluate(valid_ds)\n",
    "(1-mae)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([91.122856, 91.51319 , 91.2349  , 91.382095, 90.702225],\n",
       "       dtype=float32),\n",
       " 91.19105562567711)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.concatenate([y for x,y in valid_ds])\n",
    "y_pred = model.predict(valid_ds)\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred, multioutput='raw_values')\n",
    "(1-mae)*100, (1-np.mean(mae))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 62s 974ms/step - loss: 0.0127 - mae: 0.0895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91.05187579989433"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds = tf.data.experimental.load('./data/faces/test_ds/')\n",
    "loss, mae = model.evaluate(test_ds)\n",
    "(1-mae)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([90.81782 , 91.483826, 91.21508 , 91.05965 , 90.683   ],\n",
       "       dtype=float32),\n",
       " 91.05187132954597)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.concatenate([y for x,y in test_ds])\n",
    "y_pred = model.predict(test_ds)\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred, multioutput='raw_values')\n",
    "(1-mae)*100, (1-np.mean(mae))*100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfpy39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
