{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\21265\\anaconda3\\envs\\tfpy39\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.6.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.6.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import numpy as np \n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.experimental.load('./data/audio/train_ds/') \\\n",
    "    .cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "valid_ds = tf.data.experimental.load('./data/audio/valid_ds/') \\\n",
    "    .cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PrefetchDataset shapes: ((None, 15, 128), (None, 5)), types: (tf.float32, tf.float32)>,\n",
       " <PrefetchDataset shapes: ((None, 15, 128), (None, 5)), types: (tf.float32, tf.float32)>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Audio model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_audio_model():\n",
    "  inputs = keras.layers.Input(shape=(15,128))\n",
    "\n",
    "  x = keras.layers.Conv1D(32, 2)(inputs)\n",
    "  x = keras.layers.Dropout(0.3)(x)\n",
    "  \n",
    "  x = keras.layers.Conv1D(64, 2)(x)\n",
    "  x = keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "  x = keras.layers.LSTM(512, return_sequences=True)(x)\n",
    "  x = keras.layers.LSTM(256)(x)\n",
    "\n",
    "  x = keras.layers.Dense(256)(x)\n",
    "  x = keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "\n",
    "  x = keras.layers.Dense(5, activation='sigmoid')(x)\n",
    "\n",
    "  return keras.models.Model(inputs=inputs, outputs=x, name='audio_model')\n",
    "\n",
    "\n",
    "audio_model = make_audio_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "t = datetime.datetime.now().strftime(\"%m%d_%H%M%S\")\n",
    "\n",
    "optimizer   = tfa.optimizers.RectifiedAdam()\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=10, verbose=0)\n",
    "check_point    = keras.callbacks.ModelCheckpoint(filepath='./weights/audio/'+str(t)+'/audio.t5',\n",
    "                             monitor='val_mae',\n",
    "                             mode='min',\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True,\n",
    "                             verbose=0)\n",
    "\n",
    "audio_model.compile(loss='mse', optimizer=optimizer , metrics=['mae'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - 9s 35ms/step - loss: 0.0194 - mae: 0.1113 - val_loss: 0.0163 - val_mae: 0.1020\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - 5s 24ms/step - loss: 0.0177 - mae: 0.1061 - val_loss: 0.0161 - val_mae: 0.1009\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0174 - mae: 0.1053 - val_loss: 0.0165 - val_mae: 0.1023\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0174 - mae: 0.1052 - val_loss: 0.0174 - val_mae: 0.1055\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0171 - mae: 0.1043 - val_loss: 0.0158 - val_mae: 0.0998\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0170 - mae: 0.1040 - val_loss: 0.0178 - val_mae: 0.1053\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0168 - mae: 0.1034 - val_loss: 0.0158 - val_mae: 0.0999\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0168 - mae: 0.1036 - val_loss: 0.0158 - val_mae: 0.1002\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0171 - mae: 0.1047 - val_loss: 0.0162 - val_mae: 0.1011\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0166 - mae: 0.1027 - val_loss: 0.0160 - val_mae: 0.1005\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0164 - mae: 0.1021 - val_loss: 0.0155 - val_mae: 0.0988\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0165 - mae: 0.1026 - val_loss: 0.0158 - val_mae: 0.0997\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0162 - mae: 0.1017 - val_loss: 0.0157 - val_mae: 0.0995\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0163 - mae: 0.1016 - val_loss: 0.0160 - val_mae: 0.1004\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0164 - mae: 0.1020 - val_loss: 0.0158 - val_mae: 0.0999\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0162 - mae: 0.1015 - val_loss: 0.0153 - val_mae: 0.0983\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0160 - mae: 0.1011 - val_loss: 0.0154 - val_mae: 0.0987\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0160 - mae: 0.1009 - val_loss: 0.0155 - val_mae: 0.0989\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0159 - mae: 0.1004 - val_loss: 0.0153 - val_mae: 0.0981\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0156 - mae: 0.1000 - val_loss: 0.0157 - val_mae: 0.0994\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0156 - mae: 0.0995 - val_loss: 0.0157 - val_mae: 0.0999\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0157 - mae: 0.1003 - val_loss: 0.0160 - val_mae: 0.1005\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0154 - mae: 0.0991 - val_loss: 0.0156 - val_mae: 0.0993\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0155 - mae: 0.0994 - val_loss: 0.0153 - val_mae: 0.0983\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0153 - mae: 0.0987 - val_loss: 0.0164 - val_mae: 0.1022\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0153 - mae: 0.0988 - val_loss: 0.0163 - val_mae: 0.1013\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0151 - mae: 0.0982 - val_loss: 0.0159 - val_mae: 0.1002\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0149 - mae: 0.0975 - val_loss: 0.0155 - val_mae: 0.0988\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0150 - mae: 0.0976 - val_loss: 0.0158 - val_mae: 0.1001\n"
     ]
    }
   ],
   "source": [
    "history = audio_model.fit(train_ds, validation_data=valid_ds, batch_size=32, epochs=100, callbacks=[early_stopping, check_point])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x289228c1d00>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_model.load_weights('./weights/audio/0225_191323_9005/audio.t5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([90.441124, 89.76602 , 89.94365 , 90.76098 , 90.0224  ],\n",
       "       dtype=float32),\n",
       " 90.18683582544327)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ds = tf.data.experimental.load('./data/audio/valid_ds')\n",
    "\n",
    "y_true = np.concatenate([y for x,y in valid_ds])\n",
    "y_pred = audio_model.predict(valid_ds)\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred, multioutput='raw_values')\n",
    "(1-mae)*100, (1-np.mean(mae))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 7ms/step - loss: 0.0156 - mae: 0.0994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([90.31917 , 89.90838 , 89.861176, 90.41583 , 89.78329 ],\n",
       "       dtype=float32),\n",
       " 90.05756974220276)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds = tf.data.experimental.load('./data/audio/test_ds/')\n",
    "loss, mae = audio_model.evaluate(test_ds)\n",
    "\n",
    "\n",
    "y_true = np.concatenate([y for x,y in test_ds])\n",
    "y_pred = audio_model.predict(test_ds)\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred, multioutput='raw_values')\n",
    "(1-mae)*100, (1-np.mean(mae))*100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfpy39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
