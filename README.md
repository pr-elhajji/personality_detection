# Deep Multimodal Fusion for Personality Recognition: Integrating Visual, Audio, and Textual Modalities 
The method we propose combines information from several modalities using various fusion techniques, improving the predictive capability of the model. Experimental findings on the publicly available ChaLearn First Impressions-V2 dataset demonstrate the effectiveness of our approach, outperforming the state-of-the-art accuracy levels. This paper contributes to the advancement of multimodal deep learning techniques and provides valuable insights into the field of personality detection.

# Authors:
- Ayoub Ouaraka 
- Mohamed El Hajji
- Youssef Es-saady
- Tarek Ait Baha
