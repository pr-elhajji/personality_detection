{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\21265\\anaconda3\\envs\\tfpy39\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.6.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.6.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_hub as hub \n",
    "from sklearn.metrics import mean_absolute_error \n",
    "import numpy as np \n",
    "import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PrefetchDataset shapes: ((None, 10, 224, 224, 3), (None, 5)), types: (tf.float32, tf.float32)>,\n",
       " <PrefetchDataset shapes: ((None, 10, 224, 224, 3), (None, 5)), types: (tf.float32, tf.float32)>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = tf.data.experimental.load('./data/fullscene/train_ds') \\\n",
    "    .cache().shuffle(buffer_size=1000, seed=42).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "valid_ds = tf.data.experimental.load('./data/fullscene/valid_ds') \\\n",
    "    .cache().shuffle(buffer_size=1000, seed=42).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds, valid_ds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = keras.applications.VGG16(include_top=False, weights='imagenet', pooling='max')\n",
    "vgg16.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Vit-B16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_extractor = hub.KerasLayer(\"https://www.kaggle.com/models/spsayakpaul/vision-transformer/frameworks/TensorFlow2/variations/vit-b16-fe/versions/1/\", trainable=False) # ../../vit_b16_fe/\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build scene model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.layers.Input(shape=(10,224,224,3), name='Input')\n",
    "\n",
    "# First model \n",
    "x      = keras.layers.TimeDistributed(keras.layers.Rescaling(scale=1./255.0), name='Rescaling')(inputs)\n",
    "x      = keras.layers.TimeDistributed(vgg16, name='vgg16')(x)\n",
    "x      = keras.layers.LSTM(units=128, return_sequences=True)(x)\n",
    "x      = keras.layers.LSTM(units=64)(x)\n",
    "x      = keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "x      = keras.layers.Dense(units=1024)(x)\n",
    "x      = keras.layers.Dense(units=512, activation='relu')(x)\n",
    "\n",
    "\n",
    "# Second model \n",
    "y      = keras.layers.TimeDistributed(keras.layers.Rescaling(scale=1./127.5, offset=-1))(inputs)\n",
    "\n",
    "#vit_extractor = hub.KerasLayer(\"https://www.kaggle.com/models/spsayakpaul/vision-transformer/frameworks/TensorFlow2/variations/vit-b16-fe/versions/1/\", trainable=False) # ../../vit_b16_fe/\n",
    "vit_extractor.compute_output_shape = lambda x: (x[0], 768)\n",
    "\n",
    "y      = keras.layers.TimeDistributed(vit_extractor)(y)\n",
    "y      = keras.layers.LSTM(units=128, return_sequences=True)(y)\n",
    "y      = keras.layers.LSTM(units=64)(y)\n",
    "y      = keras.layers.Dropout(0.2)(y)\n",
    "y      = keras.layers.Dense(units=1024)(y)\n",
    "y      = keras.layers.Dense(units=512, activation='relu')(y)\n",
    "\n",
    "\n",
    "# Averaget two models\n",
    "z      = keras.layers.Average()([x,y])\n",
    "\n",
    "z      = keras.layers.Dense(256, activation='relu')(z)\n",
    "z      = keras.layers.Dropout(0.5)(z)\n",
    "\n",
    "z      = keras.layers.Dense(5, activation='sigmoid')(z)\n",
    "\n",
    "model  = keras.models.Model(inputs=inputs, outputs=z)\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = datetime.datetime.now().strftime(\"%m%d_%H%M%S\")\n",
    "\n",
    "optimizer      = tfa.optimizers.RectifiedAdam()\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=10, verbose=0)\n",
    "check_point    = keras.callbacks.ModelCheckpoint(filepath='./weights/scene/'+str(t)+'/scene.t5',\n",
    "                             monitor='val_mae',\n",
    "                             mode='min',\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True,\n",
    "                             verbose=0)\n",
    "\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mae'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - 353s 1s/step - loss: 0.0199 - mae: 0.1132 - val_loss: 0.0155 - val_mae: 0.0988\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - 217s 1s/step - loss: 0.0158 - mae: 0.1006 - val_loss: 0.0158 - val_mae: 0.1012\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - 216s 1s/step - loss: 0.0135 - mae: 0.0928 - val_loss: 0.0134 - val_mae: 0.0923\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - 216s 1s/step - loss: 0.0117 - mae: 0.0860 - val_loss: 0.0128 - val_mae: 0.0901\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - 215s 1s/step - loss: 0.0109 - mae: 0.0836 - val_loss: 0.0129 - val_mae: 0.0906\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - 216s 1s/step - loss: 0.0099 - mae: 0.0794 - val_loss: 0.0132 - val_mae: 0.0913\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - 215s 1s/step - loss: 0.0096 - mae: 0.0777 - val_loss: 0.0130 - val_mae: 0.0909\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - 215s 1s/step - loss: 0.0093 - mae: 0.0767 - val_loss: 0.0127 - val_mae: 0.0891\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - 215s 1s/step - loss: 0.0087 - mae: 0.0744 - val_loss: 0.0125 - val_mae: 0.0886\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - 216s 1s/step - loss: 0.0084 - mae: 0.0726 - val_loss: 0.0130 - val_mae: 0.0905\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - 215s 1s/step - loss: 0.0082 - mae: 0.0717 - val_loss: 0.0124 - val_mae: 0.0886\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - 215s 1s/step - loss: 0.0078 - mae: 0.0706 - val_loss: 0.0126 - val_mae: 0.0895\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - 215s 1s/step - loss: 0.0074 - mae: 0.0682 - val_loss: 0.0122 - val_mae: 0.0878\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - 216s 1s/step - loss: 0.0073 - mae: 0.0681 - val_loss: 0.0126 - val_mae: 0.0893\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - 219s 1s/step - loss: 0.0069 - mae: 0.0660 - val_loss: 0.0126 - val_mae: 0.0890\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - 216s 1s/step - loss: 0.0069 - mae: 0.0657 - val_loss: 0.0126 - val_mae: 0.0891\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - 218s 1s/step - loss: 0.0069 - mae: 0.0658 - val_loss: 0.0135 - val_mae: 0.0923\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - 222s 1s/step - loss: 0.0069 - mae: 0.0658 - val_loss: 0.0131 - val_mae: 0.0911\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - 216s 1s/step - loss: 0.0066 - mae: 0.0642 - val_loss: 0.0135 - val_mae: 0.0927\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - 216s 1s/step - loss: 0.0064 - mae: 0.0634 - val_loss: 0.0129 - val_mae: 0.0903\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - 216s 1s/step - loss: 0.0059 - mae: 0.0610 - val_loss: 0.0126 - val_mae: 0.0897\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - 220s 1s/step - loss: 0.0059 - mae: 0.0606 - val_loss: 0.0122 - val_mae: 0.0881\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - 216s 1s/step - loss: 0.0058 - mae: 0.0600 - val_loss: 0.0131 - val_mae: 0.0911\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, validation_data=valid_ds, batch_size=32, epochs=100, callbacks=[early_stopping, check_point])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x257d8b7c940>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('./weights/scene/0225_123154/scene.t5')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 116s 1s/step - loss: 0.0122 - mae: 0.0878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91.21540263295174"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ds = tf.data.experimental.load('./data/fullscene/valid_ds')\n",
    "valid_ds\n",
    "\n",
    "loss, mae = model.evaluate(valid_ds)\n",
    "(1-mae)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([91.1606 , 91.59788, 91.07107, 91.43924, 90.80823], dtype=float32),\n",
       " 91.21540412306786)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.concatenate([y for x,y in valid_ds])\n",
    "y_pred = model.predict(valid_ds)\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred, multioutput='raw_values')\n",
    "(1-mae)*100, (1-np.mean(mae))*100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 56s 888ms/step - loss: 0.0122 - mae: 0.0881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91.19265154004097"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds = tf.data.experimental.load('./data/fullscene/test_ds/')\n",
    "loss, mae = model.evaluate(test_ds)\n",
    "(1-mae)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([91.00579, 91.68425, 91.14546, 91.14734, 90.9804 ], dtype=float32),\n",
       " 91.19264855980873)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.concatenate([y for x,y in test_ds], axis=0)\n",
    "y_pred = model.predict(test_ds)\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred, multioutput='raw_values')\n",
    "(1-mae)*100, (1-np.mean(mae)) * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfpy39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
